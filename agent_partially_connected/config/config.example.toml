# Global LLM configuration
[llm]
model = "Qwen/Qwen2-VL-72B-Instruct"
base_url = "https://api.siliconflow.cn/v1"
api_key = "sk-wsrapwysdnhclrittrchadcwqauisbgoxmblzzvgfgvjrshh"
temperature = 0.1



# Optional configuration for specific LLM models
[llm.coder]
model = "UI-TARS-7B-SFT"
base_url = "http://localhost:8000/v1"
api_key = "sk-..."
temperature = 1.0

[llm.detect]
model = "Qwen/Qwen2-VL-72B-Instruct"
base_url = "https://api.siliconflow.cn/v1"
api_key = "sk-bbwqnimupumnxffvokuqwwaruvdkavfmwobugvqgxwujhdfq"